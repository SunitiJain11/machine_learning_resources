a. machine learning resources:
   udemy course 
`  https://www.geeksforgeeks.org/machine-learning/

b. machine learning project ideas list:
    https://study.com/academy/lesson/linear-regression-project-ideas.html (regression specifically)
    https://www.analyticsvidhya.com/blog/2018/05/24-ultimate-data-science-projects-to-boost-your-knowledge-and-skills/ 

c. whenever spyder says "data_set" is not present , run file by that gree arrow once, working directory might not be set for that file.

d. What is boosting algo?
    when the preidctors/classifiers are week, we combine then to form a stronog one. This is called boosting algo.
    https://data-flair.training/blogs/gradient-boosting-algorithm/
    
e. What is gradient decent?
    https://www.geeksforgeeks.org/ml-stochastic-gradient-descent-sgd/?ref=rp
    it is change in a parameter with respct to the inputs.
    A gradient is basically the slope of a function; the degree of change of a parameter with the amount of change in another parameter. Mathematically, it can be described as the partial derivatives of a set of parameters with respect to its inputs. The more the gradient, the steeper the slope. Gradient Descent is a convex function.
Gradient Descent can be described as an iterative method which is used to find the values of the parameters of a function that minimizes the cost function as much as possible.

1. data pre processing : (udemy)
https://hackernoon.com/what-steps-should-one-take-while-doing-data-preprocessing-502c993e1caa 

    1.1 for test- train split use sklearn.modelselection, not sklean.cross_validation.

    1.2 random state in test_train_split(), ensures that whenever you splt, the train-test set is same.
    
    Random state ensures that the splits that you generate are reproducible. Scikit-learn uses random permutations to    generate the splits. The random state that you provide is used as a seed to the random number generator. This ensures that the random numbers are generated in the same order.
    
    https://stackoverflow.com/questions/49147774/what-is-random-state-in-sklearn-model-selection-train-test-split-example/49147883#49147883?newreg=20d07e9d357644a2b6da4493338f2974
    
    1.3 fit_transform()
         always give an array of shape of column i.e.array=  array.resize(1,-1), not array=array.resize(-1,1).
         sinxe it only works column wise , not rows wise.

2. regression: (udemy)
 https://towardsdatascience.com/a-beginners-guide-to-linear-regression-in-python-with-scikit-learn-83a8f7ae2b4f  -for basics.
 
 
 2.1 no need of feature scaling, library already takes care.
 2.2 multiple regression : Backward elimination
    Statsmodel.api only not Statsmodel.formulae.api
 2.3 p value:
     let say I clain this feature has affect in data-> H1 , bu topposition says it has no affect->H0
     I will calculate the probsbilty of H0 happending say it P
     if P> some level(let ay significance level: alphs) : then H0 is true
     else H1 is true
     
     this p is "p value".
 2.4 regression types:
     https://www.listendata.com/2018/03/regression-analysis.html?m=1
 
 2.5 multiple regression types:
     https://en.m.wikipedia.org/wiki/Stepwise_regression 
     
 2.6 plynomial linear regression 
    2.6.1  it is called linear because the relation between y and coffiecients is linear. because at the end we need cofficients.  
     likt y = b0 + b1*x + b2*x^2 ..
     y is linearly depdendant on b0, b1, b2, etc.
     had it ben y= (b0+ x*b2)/(b3+ b4* x^4) something, then it would have been non linear.
    
    2.6.2 when dataset is small, eg, in our polynomial one, we do;t split into train. we don;t waste dataset that we have. We use it all so that we can have best prediction.
     
    2.7 gradient descent in regression
        a method to choose coefficients, so that is cost is minimum.
        https://www.geeksforgeeks.org/gradient-descent-in-linear-regression/
        here theta1, theeta 2 are b0, b2 of regression equation.
 2.7 support vector regressor
    2.7.1 what is kernel 
        https://data-flair.training/blogs/svm-kernel-functions/ 
    2.7.2 svr class doesn't do feature scaling, we need to take care of that.  
    2.7.3 reshape in python
          https://www.geeksforgeeks.org/numpy-reshape-python/
          reshapes one array to another 
    2.7.4 what is reshape(-1,x)?
          reshape means given the rows find the number of columns it self.
          https://stackoverflow.com/questions/18691084/what-does-1-mean-in-numpy-reshape
          
     
