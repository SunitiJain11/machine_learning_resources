a. machine learning resources:
`  https://www.geeksforgeeks.org/machine-learning/

b. machine learning project ideas list:
    https://study.com/academy/lesson/linear-regression-project-ideas.html (regression specifically)
    https://www.analyticsvidhya.com/blog/2018/05/24-ultimate-data-science-projects-to-boost-your-knowledge-and-skills/ 

c. whenever spyder says "data_set" is not present , run file by that gree arrow once, working directory might not be set for that file.

1. data pre processing : (udemy)
https://hackernoon.com/what-steps-should-one-take-while-doing-data-preprocessing-502c993e1caa 

    1.1 for test- train split use sklearn.modelselection, not sklean.cross_validation.

    1.2 random state in test_train_split(), ensures that whenever you splt, the train-test set is same.
    
    Random state ensures that the splits that you generate are reproducible. Scikit-learn uses random permutations to    generate the splits. The random state that you provide is used as a seed to the random number generator. This ensures that the random numbers are generated in the same order.
    
    https://stackoverflow.com/questions/49147774/what-is-random-state-in-sklearn-model-selection-train-test-split-example/49147883#49147883?newreg=20d07e9d357644a2b6da4493338f2974

2. regression: (udemy)
 https://towardsdatascience.com/a-beginners-guide-to-linear-regression-in-python-with-scikit-learn-83a8f7ae2b4f  -for basics.
 
 
 2.1 no need of feature scaling, library already takes care.
 2.2 multiple regression : Backward elimination
    Statsmodel.api only not Statsmodel.formulae.api
 2.3 p value:
     let say I clain this feature has affect in data-> H1 , bu topposition says it has no affect->H0
     I will calculate the probsbilty of H0 happending say it P
     if P> some level(let ay significance level: alphs) : then H0 is true
     else H1 is true
     
     this p is "p value".
 2.4 regression types:
     https://www.listendata.com/2018/03/regression-analysis.html?m=1
 
 2.5 multiple regression types:
     https://en.m.wikipedia.org/wiki/Stepwise_regression 
     
 2.6 plynomial linear regression 
     it is called linear because the relation between y and coffiecients is linear. because at the end we need cofficients.
     likt y = b0 + b1*x + b2*x^2 ..
     y is linearly depdendant on b0, b1, b2, etc.
     had it ben y= (b0+ x*b2)/(b3+ b4* x^4) something, then it would have been non linear.
